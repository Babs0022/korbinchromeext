{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 223, "column": 0}, "map": {"version":3,"sources":["file:///home/user/studio/src/ai/genkit.ts"],"sourcesContent":["import {genkit} from 'genkit';\nimport {googleAI} from '@genkit-ai/googleai';\n\nexport const ai = genkit({\n  plugins: [googleAI()],\n  model: 'googleai/gemini-2.5-flash',\n});\n"],"names":[],"mappings":";;;AAAA;AAAA;AACA;AAAA;;;AAEO,MAAM,KAAK,CAAA,GAAA,uIAAA,CAAA,SAAM,AAAD,EAAE;IACvB,SAAS;QAAC,CAAA,GAAA,2KAAA,CAAA,WAAQ,AAAD;KAAI;IACrB,OAAO;AACT","debugId":null}},
    {"offset": {"line": 244, "column": 0}, "map": {"version":3,"sources":["file:///home/user/studio/src/ai/flows/llm-assisted-contextual-action.ts"],"sourcesContent":["'use server';\n/**\n * @fileOverview This file defines a Genkit flow for LLM-assisted contextual actions within vibe-coding platforms.\n *\n * - llmAssistedContextualAction - A function that orchestrates the process of determining the next best action using an LLM.\n * - LLMAssistedContextualActionInput - The input type for the llmAssistedContextualAction function, including DOM snapshot and project goals.\n * - LLMAssistedContextualActionOutput - The return type for the llmAssistedContextualAction function, specifying the next action to execute.\n */\n\nimport {ai} from '@/ai/genkit';\nimport {z} from 'genkit';\n\nconst LLMAssistedContextualActionInputSchema = z.object({\n  domSnapshot: z.string().describe('A snapshot of the current DOM of the active tab.'),\n  projectGoals: z.string().describe('The high-level goals for the current project.'),\n  platform: z.string().describe('The vibe-coding platform the agent is interacting with, e.g., Firebase Studio, Replit, Vercel AI Studio.'),\n  userId: z.string().describe('The ID of the user running the agent.'),\n  projectId: z.string().describe('The ID of the project the agent is working on.'),\n});\nexport type LLMAssistedContextualActionInput = z.infer<typeof LLMAssistedContextualActionInputSchema>;\n\nconst LLMAssistedContextualActionOutputSchema = z.object({\n  response: z.string().describe(\"A friendly, conversational response to the user explaining what action is being taken and why. This should not be technical jargon, but a natural language explanation.\"),\n  action: z.string().describe('The next action to execute (e.g., click, type, navigate, none), based on the DOM and project goals. Use \"none\" if no action is required or if you are just responding to the user.'),\n  actionDetails: z.any().describe('A JSON object containing details for the action. For \"click\" or \"type\", this should include a \"selector\" key with a CSS selector. For \"type\", it should also include a \"text\" key.'),\n  reasoning: z.string().describe('The LLM agent reasoning for taking that next action, based on the project goals and the dom inspection.'),\n});\nexport type LLMAssistedContextualActionOutput = z.infer<typeof LLMAssistedContextualActionOutputSchema>;\n\nexport async function llmAssistedContextualAction(input: LLMAssistedContextualActionInput): Promise<LLMAssistedContextualActionOutput> {\n  return llmAssistedContextualActionFlow(input);\n}\n\nconst prompt = ai.definePrompt({\n  name: 'llmAssistedContextualActionPrompt',\n  input: {schema: LLMAssistedContextualActionInputSchema},\n  output: {schema: LLMAssistedContextualActionOutputSchema},\n  prompt: `You are an AI agent navigating a vibe-coding platform ({{{platform}}}) to achieve specific project goals for user {{{userId}}} on project {{{projectId}}}.\n\n  Your task is to analyze the current state of the DOM and the user's goal to determine the next best action.\n\n  1. The current DOM snapshot:\n  ----------\n  {{{domSnapshot}}}\n  ----------\n\n  2. The overall project goals:\n  ----------\n  {{{projectGoals}}}\n  ----------\n\n  Based on the above information, decide on the single, most logical next action to take. Actions can be \"click\", \"type\", \"navigate\", or \"none\".\n\n  In your response, you MUST provide two things:\n  1. A friendly, conversational \"response\" to the user. Explain what you are about to do and why, as if you were a helpful assistant. Do not use technical jargon.\n  2. The structured action plan (action, actionDetails, reasoning) to be executed by the system.\n\n  Example: If the goal is \"click the login button\", your response might be:\n  - response: \"Okay, I see the login button. I'll click it now to proceed.\"\n  - action: \"click\"\n  - actionDetails: { \"selector\": \"button.login\" }\n  - reasoning: \"The user's goal is to log in, and the button with the 'login' class is the clear next step.\"\n\n  If no action is needed, you can simply respond to the user.\n  - response: \"I've analyzed the page, and it looks like we're already on the right track. What should I do next?\"\n  - action: \"none\"\n  - actionDetails: {}\n  - reasoning: \"The current page state aligns with the user's goal, so no immediate UI action is necessary.\"\n`,\n});\n\nconst llmAssistedContextualActionFlow = ai.defineFlow(\n  {\n    name: 'llmAssistedContextualActionFlow',\n    inputSchema: LLMAssistedContextualActionInputSchema,\n    outputSchema: LLMAssistedContextualActionOutputSchema,\n  },\n  async input => {\n    const {output} = await prompt(input);\n    return output!;\n  }\n);\n"],"names":[],"mappings":";;;;;AACA;;;;;;CAMC,GAED;AACA;AAAA;;;;;;AAEA,MAAM,yCAAyC,uIAAA,CAAA,IAAC,CAAC,MAAM,CAAC;IACtD,aAAa,uIAAA,CAAA,IAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;IACjC,cAAc,uIAAA,CAAA,IAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;IAClC,UAAU,uIAAA,CAAA,IAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;IAC9B,QAAQ,uIAAA,CAAA,IAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;IAC5B,WAAW,uIAAA,CAAA,IAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;AACjC;AAGA,MAAM,0CAA0C,uIAAA,CAAA,IAAC,CAAC,MAAM,CAAC;IACvD,UAAU,uIAAA,CAAA,IAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;IAC9B,QAAQ,uIAAA,CAAA,IAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;IAC5B,eAAe,uIAAA,CAAA,IAAC,CAAC,GAAG,GAAG,QAAQ,CAAC;IAChC,WAAW,uIAAA,CAAA,IAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;AACjC;AAGO,eAAe,4BAA4B,KAAuC;IACvF,OAAO,gCAAgC;AACzC;AAEA,MAAM,SAAS,mHAAA,CAAA,KAAE,CAAC,YAAY,CAAC;IAC7B,MAAM;IACN,OAAO;QAAC,QAAQ;IAAsC;IACtD,QAAQ;QAAC,QAAQ;IAAuC;IACxD,QAAQ,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA+BX,CAAC;AACD;AAEA,MAAM,kCAAkC,mHAAA,CAAA,KAAE,CAAC,UAAU,CACnD;IACE,MAAM;IACN,aAAa;IACb,cAAc;AAChB,GACA,OAAM;IACJ,MAAM,EAAC,MAAM,EAAC,GAAG,MAAM,OAAO;IAC9B,OAAO;AACT;;;IAnDoB;;AAAA,+OAAA","debugId":null}},
    {"offset": {"line": 339, "column": 0}, "map": {"version":3,"sources":["file:///home/user/studio/src/ai/flows/llm-generate-chat-name.ts"],"sourcesContent":["'use server';\n/**\n * @fileOverview This file defines a Genkit flow for generating a concise chat name from the first message.\n *\n * - generateChatName - A function that takes the first user message and returns a suggested chat name.\n * - GenerateChatNameInput - The input type for the generateChatName function.\n * - GenerateChatNameOutput - The return type for the generateChatName function.\n */\n\nimport {ai} from '@/ai/genkit';\nimport {z} from 'genkit';\n\nconst GenerateChatNameInputSchema = z.object({\n  message: z.string().describe('The first message from the user in a new chat session.'),\n});\nexport type GenerateChatNameInput = z.infer<typeof GenerateChatNameInputSchema>;\n\nconst GenerateChatNameOutputSchema = z.object({\n  name: z.string().describe('A short, concise name for the chat session, no more than 5 words.'),\n});\nexport type GenerateChatNameOutput = z.infer<typeof GenerateChatNameOutputSchema>;\n\nexport async function generateChatName(input: GenerateChatNameInput): Promise<GenerateChatNameOutput> {\n  return generateChatNameFlow(input);\n}\n\nconst prompt = ai.definePrompt({\n  name: 'generateChatNamePrompt',\n  input: {schema: GenerateChatNameInputSchema},\n  output: {schema: GenerateChatNameOutputSchema},\n  prompt: `You are an AI assistant that creates short, descriptive titles for chat sessions. Based on the user's first message, generate a concise name for the conversation. The name should be no more than 5 words.\n\n  User Message:\n  ----------\n  {{{message}}}\n  ----------\n`,\n});\n\nconst generateChatNameFlow = ai.defineFlow(\n  {\n    name: 'generateChatNameFlow',\n    inputSchema: GenerateChatNameInputSchema,\n    outputSchema: GenerateChatNameOutputSchema,\n  },\n  async input => {\n    const {output} = await prompt(input);\n    return output!;\n  }\n);\n"],"names":[],"mappings":";;;;;AACA;;;;;;CAMC,GAED;AACA;AAAA;;;;;;AAEA,MAAM,8BAA8B,uIAAA,CAAA,IAAC,CAAC,MAAM,CAAC;IAC3C,SAAS,uIAAA,CAAA,IAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;AAC/B;AAGA,MAAM,+BAA+B,uIAAA,CAAA,IAAC,CAAC,MAAM,CAAC;IAC5C,MAAM,uIAAA,CAAA,IAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;AAC5B;AAGO,eAAe,iBAAiB,KAA4B;IACjE,OAAO,qBAAqB;AAC9B;AAEA,MAAM,SAAS,mHAAA,CAAA,KAAE,CAAC,YAAY,CAAC;IAC7B,MAAM;IACN,OAAO;QAAC,QAAQ;IAA2B;IAC3C,QAAQ;QAAC,QAAQ;IAA4B;IAC7C,QAAQ,CAAC;;;;;;AAMX,CAAC;AACD;AAEA,MAAM,uBAAuB,mHAAA,CAAA,KAAE,CAAC,UAAU,CACxC;IACE,MAAM;IACN,aAAa;IACb,cAAc;AAChB,GACA,OAAM;IACJ,MAAM,EAAC,MAAM,EAAC,GAAG,MAAM,OAAO;IAC9B,OAAO;AACT;;;IA1BoB;;AAAA,+OAAA","debugId":null}},
    {"offset": {"line": 402, "column": 0}, "map": {"version":3,"sources":["file:///home/user/studio/.next-internal/server/app/page/actions.js%20%28server%20actions%20loader%29"],"sourcesContent":["export {llmAssistedContextualAction as '40997276c665ad75bfe4b434f19ef5631ba43e8620'} from 'ACTIONS_MODULE0'\nexport {generateChatName as '40bc2d8e24cc0324833c3ca84f3642a747ad4a78d3'} from 'ACTIONS_MODULE1'\n"],"names":[],"mappings":";AAAA;AACA","debugId":null}},
    {"offset": {"line": 460, "column": 0}, "map": {"version":3,"sources":["file:///home/user/studio/src/app/page.tsx/proxy.mjs"],"sourcesContent":["import { registerClientReference } from \"react-server-dom-turbopack/server.edge\";\nexport default registerClientReference(\n    function() { throw new Error(\"Attempted to call the default export of [project]/src/app/page.tsx <module evaluation> from the server, but it's on the client. It's not possible to invoke a client function from the server, it can only be rendered as a Component or passed to props of a Client Component.\"); },\n    \"[project]/src/app/page.tsx <module evaluation>\",\n    \"default\",\n);\n"],"names":[],"mappings":";;;AAAA;;uCACe,CAAA,GAAA,qPAAA,CAAA,0BAAuB,AAAD,EACjC;IAAa,MAAM,IAAI,MAAM;AAAoR,GACjT,kDACA","debugId":null}},
    {"offset": {"line": 474, "column": 0}, "map": {"version":3,"sources":["file:///home/user/studio/src/app/page.tsx/proxy.mjs"],"sourcesContent":["import { registerClientReference } from \"react-server-dom-turbopack/server.edge\";\nexport default registerClientReference(\n    function() { throw new Error(\"Attempted to call the default export of [project]/src/app/page.tsx from the server, but it's on the client. It's not possible to invoke a client function from the server, it can only be rendered as a Component or passed to props of a Client Component.\"); },\n    \"[project]/src/app/page.tsx\",\n    \"default\",\n);\n"],"names":[],"mappings":";;;AAAA;;uCACe,CAAA,GAAA,qPAAA,CAAA,0BAAuB,AAAD,EACjC;IAAa,MAAM,IAAI,MAAM;AAAgQ,GAC7R,8BACA","debugId":null}},
    {"offset": {"line": 488, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"","debugId":null}}]
}